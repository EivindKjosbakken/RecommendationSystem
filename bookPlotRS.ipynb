{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "from numpy.linalg import norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data test\n",
    "loaded_array1 = np.load('../../data/NPZ/titleAndEncodedSummariesStrings1.npz', allow_pickle = True)\n",
    "print((loaded_array1[\"arr_0\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def preProcessString(string: str):\n",
    "    \n",
    "    # remove stopwords\n",
    "    word_tokens = word_tokenize(string)\n",
    "    string = (\" \".join([w for w in word_tokens if not w.lower() in stop_words]))\n",
    "\n",
    "    # all lower case\n",
    "    string = string.lower()\n",
    "    # spell check\n",
    "    word_tokens = word_tokenize(string)\n",
    "\n",
    "    #skip since it takes too long\n",
    "    # spell = Speller(lang='en')\n",
    "    # string = (\" \".join([spell(w) for w in word_tokens]))\n",
    "\n",
    "    # stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    string = (' '.join(stemmer.stem(token) for token in word_tokenize(string)))\n",
    "\n",
    "    return string\t\n",
    "\n",
    "def preProcessListOfStrings(strings : list):\n",
    "    return [preProcessString(string) for string in strings]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for all summaries in each file, store preprocessed and vectorized summaries in new numpy files\n",
    "\n",
    "def saveVectorizedSummaries():\n",
    "    \"\"\"save all book info and vectorized summary to 1 numpy file\"\"\"\n",
    "\n",
    "    allBookTitles = []\n",
    "    allBookIsbns = []\n",
    "    #make an \"empty\" array we can concatenate to, then remove this first row before returning\n",
    "    allVectorizedSummaries = np.zeros((1, 512))\n",
    "    \n",
    "    for i in range(1, 14): #13 files\n",
    "        filepath = \"../../data/NPZ/\"\n",
    "        filename = f\"titleAndEncodedSummariesStrings{i}.npz\"\n",
    "        loaded_arrays = np.load(filepath + filename, allow_pickle = True)[\"arr_0\"]\n",
    "\n",
    "        # add book title + isbn so the list stays flattened\n",
    "        for row in loaded_arrays[:, :2]:\n",
    "            allBookTitles.append(row[0])\n",
    "            allBookIsbns.append(row[1])\n",
    "        \n",
    "        preprocessedSummaries = preProcessListOfStrings(loaded_arrays[:, 2])\n",
    "        vectorizedSummaries = embed(preprocessedSummaries)\n",
    "        allVectorizedSummaries = np.concatenate((allVectorizedSummaries, vectorizedSummaries), axis = 0)\n",
    "\n",
    "    #remove first row\n",
    "    allVectorizedSummaries = allVectorizedSummaries[1:,:]\n",
    "\n",
    "    np.save(f\"data/allBookTitles.npy\", allBookTitles)\n",
    "    np.save(f\"data/allBookIsbns.npy\", allBookIsbns)\n",
    "    np.save(f\"data/allVectorizedBookSummaries.npy\", allVectorizedSummaries)\n",
    "\n",
    "# saveVectorizedSummaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try saving summaries as npy\n",
    "#NOTE:\n",
    "#-> saving in npz takes same amount of space as saving in npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare similarities between all books\n",
    "def compareSimilarities():\n",
    "    \"\"\"compare similarities between all books. Store result in a matrix. Do not look at book titles here, but that can be inferred from the order\"\"\"\n",
    "\n",
    "    allSummaries = np.load(f\"data/allVectorizedBookSummaries.npy\")\n",
    "    similarities = np.dot(allSummaries, allSummaries.T)/(norm(allSummaries)*norm(allSummaries.T)) #cosine similarity\n",
    "    np.save(f\"data/similarities.npy\", similarities)\n",
    "\n",
    "compareSimilarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27514,)\n",
      "(27514, 512)\n",
      "(27514,)\n"
     ]
    }
   ],
   "source": [
    "#make sure lengths are correct\n",
    "# similarities = np.load(\"data/similarities.npy\")\n",
    "titles = np.load(\"data/allBookTitles.npy\")\n",
    "summaries = np.load(\"data/allVectorizedBookSummaries.npy\")\n",
    "isbns = np.load(\"data/allBookIsbns.npy\")\n",
    "print(titles.shape)\n",
    "print(summaries.shape)\n",
    "print(isbns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dune: House Harkonnen',\n",
       " 'Hunters of Dune',\n",
       " 'Kings of the Wyld',\n",
       " 'Yavana Rani',\n",
       " 'Marvel 1602',\n",
       " 'Line of Delirium',\n",
       " 'Hidden Warrior',\n",
       " 'Cymbeline',\n",
       " 'New Worlds (comics)',\n",
       " 'Darkhouse']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a function to input an isbn, which then checks which book it is, and returns the top n most similar books\n",
    "def returnTopNSimilarBooksWithIsbn(isbn: str, n: int):\n",
    "\t\"\"\"input an isbn, which then checks which book it is, and returns the top n most similar books (their isbns)\"\"\"\n",
    "\n",
    "\t#get index of book\n",
    "\tisbns = np.load(f\"data/allBookIsbns.npy\")\n",
    "\tbookIndex = np.where(isbns == isbn)[0][0]\n",
    "\n",
    "\t# #get similarities\n",
    "\tsimilarities = np.load(f\"data/similarities.npy\")\n",
    "\tbookSimilarities = similarities[bookIndex] #all similarities for this book\n",
    "\n",
    "\t# #get top n most similar books\n",
    "\ttopNIndices = (np.argsort(bookSimilarities)[::-1])[:n+1] #argsort, reverse order so most similar elements first, then take top n\n",
    "\tprint(topNIndices)\n",
    "\n",
    "\trecommendedBookIsbns = []\n",
    "\tfor idx in topNIndices:\n",
    "\t\tif (isbns[idx] != isbn):\n",
    "\t\t\trecommendedBookIsbns.append(isbns[idx])\n",
    "\treturn recommendedBookIsbns\t\n",
    "\n",
    "def returnTopNSimilarBooksWithTitle(title: str, n: int):\n",
    "\t\"\"\"input a title, which then checks which book it is, and returns the top n most similar books (their titles)\"\"\"\n",
    "\n",
    "\t#get index of book\n",
    "\ttitles = np.load(f\"data/allBookTitles.npy\")\n",
    "\tbookIndex = np.where(titles == title)[0][0]\n",
    "\n",
    "\t# #get similarities\n",
    "\tsimilarities = np.load(f\"data/similarities.npy\")\n",
    "\tbookSimilarities = similarities[bookIndex] #all similarities for this book\n",
    "\n",
    "\t# #get top n most similar books\n",
    "\ttopNIndices = (np.argsort(bookSimilarities)[::-1])[:n+1] #argsort, reverse order so most similar elements first, then take top n\n",
    "\n",
    "\trecommendedBookTitles = []\n",
    "\tfor idx in topNIndices:\n",
    "\t\tif (titles[idx] != title):\n",
    "\t\t\trecommendedBookTitles.append(titles[idx])\n",
    "\treturn recommendedBookTitles\t\n",
    "\n",
    "\n",
    "# returnTopNSimilarBooks(\"9780820312132\", 10) #num 1 (first)\n",
    "# returnTopNSimilarBooks(\"9781504318402\", 10) #num 5\n",
    "returnTopNSimilarBooksWithTitle(\"Dune (novel)\", 10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
